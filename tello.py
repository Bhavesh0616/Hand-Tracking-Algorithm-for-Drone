#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
This script connects to the DJI Tello drone, starts its live video stream, and
uses MediaPipe to detect hand keypoints from the Tello feed. Based on the position
of the hand (using the wrist as an approximation for the palm), the drone is commanded
to move left, right, up, or down.

Press 'q' in the video window to exit, at which point the drone will land.
"""

import csv
import copy
import argparse
import itertools
from collections import Counter
from collections import deque
import time
import os
import cv2 as cv
import numpy as np
import mediapipe as mp
import socket

from utils import CvFpsCalc
from model.keypoint_classifier.keypoint_classifier import KeyPointClassifier
from model.point_history_classifier.point_history_classifier import PointHistoryClassifier

from djitellopy import Tello


# Function to write hand coordinates to a file
def write_coordinates_to_file(x, y):
    try:
        with open("hand_coordinates.txt", "a") as coord_file:  # Overwrite file with new coordinates
         coord_file.write(f"{x},{y}\n")
        print(f'Coordinates logged: x={x}, y={y} at {time.time()}')

    except Exception as e:
        print(f"Error writing coordinates to file: {e}")


def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--device", type=int, default=0)
    parser.add_argument("--width", help='cap width', type=int, default=960)
    parser.add_argument("--height", help='cap height', type=int, default=540)

    parser.add_argument('--use_static_image_mode', action='store_true')
    parser.add_argument("--min_detection_confidence",
                        help='min_detection_confidence',
                        type=float,
                        default=0.7)
    parser.add_argument("--min_tracking_confidence",
                        help='min_tracking_confidence',
                        type=int,
                        default=0.5)

    args = parser.parse_args()

    return args

# Track palm movement function (new)
def track_palm_movement(hand_landmarks, frame, tello):
    # Get frame dimensions
    image_width, image_height = frame.shape[1], frame.shape[0]
    # Use the first landmark (wrist) as an approximation for the palm position.
    palm_x = int(hand_landmarks.landmark[0].x * image_width)
    palm_y = int(hand_landmarks.landmark[0].y * image_height)

    # Define the center and thresholds for movement detection.
    CENTER_X = image_width // 2
    CENTER_Y = image_height // 2
    THRESHOLD = 50       # Minimum distance (in pixels) from the center to trigger movement
    MOVE_DISTANCE = 20   # Distance (in cm) that Tello will move per command

    # Check for horizontal movement:
    if palm_x < CENTER_X - THRESHOLD:
        tello.move_left(MOVE_DISTANCE)
        print("Moving Left")
    elif palm_x > CENTER_X + THRESHOLD:
        tello.move_right(MOVE_DISTANCE)
        print("Moving Right")

    # Check for vertical movement:
    if palm_y < CENTER_Y - THRESHOLD:
        tello.move_up(MOVE_DISTANCE)
        print("Moving Up")
    elif palm_y > CENTER_Y + THRESHOLD:
        tello.move_down(MOVE_DISTANCE)
        print("Moving Down")

    return palm_x, palm_y

def main():
    tello = Tello(retry_count=1)
    tello.connect()
    print(f"Tello Battery: {tello.get_battery()}%")

    tello.streamon()  # Start video stream
    frame_read = tello.get_frame_read()  # Get video feed from Tello
    time.sleep(2)  # Allow time for the stream to initialize

    # Initialize MediaPipe Hands
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=False,  # Real-time processing
        max_num_hands=1,
        min_detection_confidence=0.7,
        min_tracking_confidence=0.7
    )
    mp_draw = mp.solutions.drawing_utils

    # Load gesture classifier
    keypoint_classifier = KeyPointClassifier()
    with open('model/keypoint_classifier/keypoint_classifier_label.csv', encoding='utf-8-sig') as f:
        keypoint_classifier_labels = [row[0] for row in csv.reader(f)]

    gesture_buffer = deque(maxlen=3)  # Reduce buffer size for faster detection
    in_air = False  # Track if the drone is flying
    takeoff_altitude = None  # Store initial takeoff height

    try:
        while True:
            for _ in range(3):  # Skip old frames to reduce lag
                frame = frame_read.frame  # Fetch latest frame

            frame = cv.resize(frame, (960, 720))  # Increase resolution for better hand tracking
            frame = cv.flip(frame, 1)
            frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
            frame_rgb.flags.writeable = False  # Fix for MediaPipe processing
            results = hands.process(frame_rgb)
            frame_rgb.flags.writeable = True

            recognized_gesture = "None"

            if results and results.multi_hand_landmarks:
                print("ğŸ– Hand detected!")  # Debugging: Confirm hand detection
                for hand_landmarks in results.multi_hand_landmarks:
                    # Draw landmarks
                    mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                    # Process keypoints
                    landmark_list = calc_landmark_list(frame, hand_landmarks)
                    processed_landmarks = pre_process_landmark(landmark_list)

                    # Recognize gesture
                    hand_sign_id = keypoint_classifier(processed_landmarks)
                    recognized_gesture = keypoint_classifier_labels[hand_sign_id]

                    # Gesture buffer for smoothing
                    gesture_buffer.append(recognized_gesture)

                    # Ensure gesture is **consistent for at least 3 frames** before executing
                    if len(gesture_buffer) == gesture_buffer.maxlen:
                        smoothed_gesture = max(set(gesture_buffer), key=gesture_buffer.count)
                    else:
                        smoothed_gesture = "None"

                    # Display recognized gesture
                    cv.putText(frame, f"Gesture: {smoothed_gesture}", (10, 50),
                               cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                    # **Drone Control Logic**
                    if smoothed_gesture == "Open" and not in_air:
                        print("ğŸš€ Taking Off")
                        tello.takeoff()
                        in_air = True
                        time.sleep(3)  # Allow video stream to stabilize

                        # Store takeoff altitude
                        takeoff_altitude = tello.get_height()
                        print(f"ğŸ“ Takeoff Altitude Recorded: {takeoff_altitude} cm")
                    
                    elif smoothed_gesture == "Open" and in_air:
                        print("ğŸ›‘ Stabilizing at Takeoff Position")
                        if takeoff_altitude is not None:
                            current_altitude = tello.get_height()
                            altitude_error = takeoff_altitude - current_altitude
                            if abs(altitude_error) > 5:  # Adjust only if deviation is significant
                                tello.send_rc_control(0, 0, int(0.5 * altitude_error), 0)
                        track_open_movement(hand_landmarks, frame, tello)

                    elif smoothed_gesture == "Close" and in_air:
                        print("ğŸ›¬ Landing")
                        tello.land()
                        in_air = False
                        takeoff_altitude = None  # Reset takeoff height
                        time.sleep(2)

                    elif smoothed_gesture == "Pointer" and in_air:
                        tello.send_rc_control(0, -20, 0, 0)  # Move backward smoothly
                        print("â†©ï¸ Moving Backward")

                    elif smoothed_gesture == "Pointer" and not in_air:
                        tello.send_rc_control(0, 20, 0, 0)  # Move forward smoothly
                        print("â¡ï¸ Moving Forward")

                    else:
                        if in_air:
                            tello.send_rc_control(0, 0, 0, 0)  # Hover if no command

            else:
                print("âš ï¸ No hand detected!")  # Debugging: If no hand is detected

            cv.imshow("Tello Hand Control", frame)

            # Exit if 'q' is pressed
            key = cv.waitKey(1) & 0xFF
            if key == ord('q'):
                break

    except Exception as e:
        print(f"âš ï¸ An error occurred: {e}")

    finally:
        print("ğŸ›¬ Landing and shutting down...")
        tello.land()
        time.sleep(2)
        tello.streamoff()
        cv.destroyAllWindows()


def select_mode(key, mode):
    number = -1
    if 48 <= key <= 57:  # 0 ~ 9
        number = key - 48
    if key == 110:  # n
        mode = 0
    if key == 107:  # k
        mode = 1
    if key == 104:  # h
        mode = 2
    return number, mode

def calc_bounding_rect(image, landmarks):
    image_width, image_height = image.shape[1], image.shape[0]

    landmark_array = np.empty((0, 2), int)

    for _, landmark in enumerate(landmarks.landmark):
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)

        landmark_point = [np.array((landmark_x, landmark_y))]

        landmark_array = np.append(landmark_array, landmark_point, axis=0)

    x, y, w, h = cv.boundingRect(landmark_array)

    return [x, y, x + w, y + h]

def calc_landmark_list(image, landmarks):
    image_width, image_height = image.shape[1], image.shape[0]

    landmark_point = []

    # Keypoint
    for _, landmark in enumerate(landmarks.landmark):
        landmark_x = min(int(landmark.x * image_width), image_width - 1)
        landmark_y = min(int(landmark.y * image_height), image_height - 1)
        # landmark_z = landmark.z

        landmark_point.append([landmark_x, landmark_y])

    return landmark_point

def pre_process_landmark(landmark_list):
    temp_landmark_list = copy.deepcopy(landmark_list)

    # Convert to relative coordinates
    base_x, base_y = 0, 0
    for index, landmark_point in enumerate(temp_landmark_list):
        if index == 0:
            base_x, base_y = landmark_point[0], landmark_point[1]

        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x
        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y

    # Convert to a one-dimensional list
    temp_landmark_list = list(
        itertools.chain.from_iterable(temp_landmark_list))

    # Normalization
    max_value = max(list(map(abs, temp_landmark_list)))

    def normalize_(n):
        return n / max_value

    temp_landmark_list = list(map(normalize_, temp_landmark_list))

    return temp_landmark_list

def pre_process_point_history(image, point_history):
    image_width, image_height = image.shape[1], image.shape[0]

    temp_point_history = copy.deepcopy(point_history)

    # Convert to relative coordinates
    base_x, base_y = 0, 0
    for index, point in enumerate(temp_point_history):
        if index == 0:
            base_x, base_y = point[0], point[1]

        temp_point_history[index][0] = (temp_point_history[index][0] -
                                        base_x) / image_width
        temp_point_history[index][1] = (temp_point_history[index][1] -
                                        base_y) / image_height

    # Convert to a one-dimensional list
    temp_point_history = list(
        itertools.chain.from_iterable(temp_point_history))

    return temp_point_history

def logging_csv(number, mode, landmark_list, point_history_list):
    if mode == 0:
        pass
    if mode == 1 and (0 <= number <= 9):
        csv_path = 'F:\\Project - D\\hand-gesture-recognition-mediapipe-main\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.csv'
        with open(csv_path, 'a', newline="") as f:
            writer = csv.writer(f)
            writer.writerow([number, *landmark_list])
    if mode == 2 and (0 <= number <= 9):
        csv_path = 'F:\\Project - D\\hand-gesture-recognition-mediapipe-main\\hand-gesture-recognition-mediapipe-main\\model\\point_history_classifier\\point_history.csv'
        with open(csv_path, 'a', newline="") as f:
            writer = csv.writer(f)
            writer.writerow([number, *point_history_list])
    return

def draw_landmarks(image, landmark_point):
    if len(landmark_point) > 0:
        # Thumb
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),
                (255, 255, 255), 2)

        # Index finger
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),
                (255, 255, 255), 2)

        # Middle finger
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),
                (255, 255, 255), 2)

        # Ring finger
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),
                (255, 255, 255), 2)

       # Little finger
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),
                (255, 255, 255), 2)

        # Palm
        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),
                (255, 255, 255), 2)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),
                (0, 0, 0), 6)
        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),
                (255, 255, 255), 2)

    # Key Points
    for index, landmark in enumerate(landmark_point):
        if index == 0:  # æ‰‹é¦–1
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 1:  # æ‰‹é¦–2
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 2:  # è¦ªæŒ‡ï¼šä»˜ã‘æ ¹
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 3:  # è¦ªæŒ‡ï¼šç¬¬1é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 4:  # è¦ªæŒ‡ï¼šæŒ‡å…ˆ
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 5:  # äººå·®æŒ‡ï¼šä»˜ã‘æ ¹
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 6:  # äººå·®æŒ‡ï¼šç¬¬2é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 7:  # äººå·®æŒ‡ï¼šç¬¬1é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 8:  # äººå·®æŒ‡ï¼šæŒ‡å…ˆ
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 9:  # ä¸­æŒ‡ï¼šä»˜ã‘æ ¹
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 10:  # ä¸­æŒ‡ï¼šç¬¬2é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 11:  # ä¸­æŒ‡ï¼šç¬¬1é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 12:  # ä¸­æŒ‡ï¼šæŒ‡å…ˆ
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 13:  # è–¬æŒ‡ï¼šä»˜ã‘æ ¹
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 14:  # è–¬æŒ‡ï¼šç¬¬2é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 15:  # è–¬æŒ‡ï¼šç¬¬1é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 16:  # è–¬æŒ‡ï¼šæŒ‡å…ˆ
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)
        if index == 17:  # å°æŒ‡ï¼šä»˜ã‘æ ¹
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 18:  # å°æŒ‡ï¼šç¬¬2é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 19:  # å°æŒ‡ï¼šç¬¬1é–¢ç¯€
            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)
        if index == 20:  # å°æŒ‡ï¼šæŒ‡å…ˆ
            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),
                      -1)
            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)

    return image

def draw_bounding_rect(use_brect, image, brect):
    if use_brect:
        # Outer rectangle
        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),
                     (0, 0, 0), 1)
    return image


def draw_info_text(image, brect, handedness, hand_sign_text, finger_gesture_text):
    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),
                 (0, 0, 0), -1)

    info_text = handedness.classification[0].label[0:]
    if hand_sign_text != "":
        info_text = info_text + ':' + hand_sign_text
    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),
               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)

    if finger_gesture_text != "":
        cv.putText(image, "Finger Gesture:" + finger_gesture_text, (10, 60),
                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)
        cv.putText(image, "Finger Gesture:" + finger_gesture_text, (10, 60),
                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,
                   cv.LINE_AA)

    return image


def draw_point_history(image, point_history):
    for index, point in enumerate(point_history):
        if point[0] != 0 and point[1] != 0:
            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),
                      (152, 251, 152), 2)
    return image


def draw_info(image, fps, mode, number):
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (0, 0, 0), 4, cv.LINE_AA)
    cv.putText(image, "FPS:" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,
               1.0, (255, 255, 255), 2, cv.LINE_AA)

    mode_string = ['Logging Key Point', 'Logging Point History']
    if 1 <= mode <= 2:
        cv.putText(image, "MODE:" + mode_string[mode - 1], (10, 90),
                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                   cv.LINE_AA)
        if 0 <= number <= 9:
            cv.putText(image, "NUM:" + str(number), (10, 110),
                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,
                       cv.LINE_AA)
    return image

if __name__ == "__main__":
    main()

